{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e259402bd08ed",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import neuroglancer\n",
    "import neuroglancer.static_file_server\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "from pytools import HedwigZarrImages\n",
    "\n",
    "from dask.distributed import LocalCluster\n",
    "import jinja2\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f6936c-b7d9-4a10-8ad5-347d050fcca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = Path(\"/Users/blowekamp/scratch/hedwig/TestData/Nanostringfiles/ROI Alignment Images for Brad/\")\n",
    "server = neuroglancer.static_file_server.StaticFileServer(\n",
    "        static_dir=file_dir, bind_address=\"localhost\", daemon=True\n",
    "    )\n",
    "viewer = neuroglancer.Viewer()\n",
    "\n",
    "shader_parameter_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e8627-945d-452a-bc69-ea33dbc64d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def homogeneous_identity(N) -> np.array:    \n",
    "    return np.identity(N+1)[:N,:]\n",
    "\n",
    "\n",
    "def sitk_offset_from_transform( tx: sitk.Transform ) :        \n",
    "    return tx.TransformPoint((0,)*tx.GetDimension())\n",
    "\n",
    "def sitk_transform_to_ng_transform( tx: sitk.Transform ):\n",
    "    \n",
    "  tx = tx.GetInverse()\n",
    "  tx_matrix = np.array(tx.GetMatrix()).reshape(tx.GetDimension(),tx.GetDimension())\n",
    "\n",
    "  M = homogeneous_identity(5)\n",
    "  M[4,4] = tx_matrix[0,0]\n",
    "  M[3,4] = tx_matrix[1,0]\n",
    "  M[4,3] = tx_matrix[0,1]\n",
    "  M[3,3] = tx_matrix[1,1]    \n",
    "\n",
    "  tx_translation = sitk_offset_from_transform(tx)\n",
    "  M[4,5] = (tx_translation[0])*1e3\n",
    "  M[3,5] = (tx_translation[1])*1e3\n",
    "\n",
    "  output_dimensions = neuroglancer.CoordinateSpace( names=[\"t'\", \"c^\", \"z\", \"y\", \"x\"], units =[\"\", \"\", \"nm\",\"nm\", \"nm\"], scales=[1,1,1,1,1])\n",
    "  ng_transform = neuroglancer.CoordinateSpaceTransform(output_dimensions=output_dimensions,\n",
    "                                                     matrix = M)\n",
    "  return ng_transform\n",
    "\n",
    "def add_zarr_image(viewer_txn, zarr_filename, transform_filename=None ):\n",
    "  \n",
    "  zarr_root = Path(zarr_filename).parent\n",
    "  zarr_key = int(Path(zarr_filename).name)\n",
    "  \n",
    "  layername = f\"{zarr_root.name}/{zarr_key}\"\n",
    "  output_dimensions = neuroglancer.CoordinateSpace( names=[\"t'\", \"c^\", \"z\", \"y\", \"x\"], units =[\"\", \"\", \"nm\",\"nm\", \"nm\"], scales=[1,1,1,1,1])\n",
    "  \n",
    "  if transform_filename:\n",
    "    tx = sitk.ReadTransform(transform_filename)\n",
    "    ng_transform = sitk_transform_to_ng_transform(tx)\n",
    "  else:\n",
    "    M = homogeneous_identity(5)\n",
    "    ng_transform = neuroglancer.CoordinateSpaceTransform(output_dimensions=output_dimensions,\n",
    "                                                     matrix = M)\n",
    "    \n",
    "  viewer_txn.layers[layername] = neuroglancer.ImageLayer(\n",
    "            source=neuroglancer.LayerDataSource(f\"zarr://{server.url}/{zarr_filename}\",\n",
    "                                               transform=ng_transform),\n",
    "            shader=generate_ng_shader(file_dir/zarr_root, zarr_key),\n",
    "        )\n",
    "  \n",
    "\n",
    "def add_roi_annotations(viewer_txn, ome_xml_filename, *, layername=\"roi annotation\", reference_zarr=None):\n",
    "\n",
    "    scales= [398, 396]\n",
    "    if reference_zarr:\n",
    "        \n",
    "        zarr_root = Path(reference_zarr).parent\n",
    "        zarr_key = int(Path(reference_zarr).name)\n",
    "        hwz_images = HedwigZarrImages(zarr_root)\n",
    "        hwz_image = hwz_images[list(hwz_images.get_series_keys())[zarr_key]]\n",
    "        spacing_tczyx = hwz_image.spacing\n",
    "        # select X and Y scales and convert to nm from um\n",
    "        scales = [s*1e3 for s in spacing_tczyx[:2:-1]]\n",
    "        \n",
    "\n",
    "    xml_path = Path(ome_xml_filename)\n",
    "    \n",
    "    ns = {\"OME\": \"http://www.openmicroscopy.org/Schemas/OME/2016-06\"}\n",
    "    with open(xml_path, \"r\") as fp:\n",
    "        data = fp.read()\n",
    "        xml_root = ET.fromstring(data)\n",
    "\n",
    "    layer = neuroglancer.LocalAnnotationLayer(\n",
    "                dimensions=neuroglancer.CoordinateSpace(\n",
    "                    names=[\"x\", \"y\"],\n",
    "                    units=\"nm\",\n",
    "                    scales=scales,\n",
    "                ),\n",
    "                \n",
    "        )\n",
    "    \n",
    "    viewer_txn.layers[layername]=layer\n",
    "    \n",
    "\n",
    "\n",
    "    # Coordinates are in the space of the original input image. The dimensions/CooridinateSpace map the index space to physical space.\n",
    "    for roi in xml_root.iterfind(\"OME:ROI\", ns):\n",
    "        for r in roi.iterfind(\"./OME:Union/OME:Rectangle\", ns):\n",
    "            height = float(r.attrib[\"Height\"])\n",
    "            width = float(r.attrib[\"Width\"])\n",
    "            x = float(r.attrib[\"X\"])\n",
    "            y = float(r.attrib[\"Y\"])\n",
    "            \n",
    "            a = (x, y)\n",
    "            b = (x+width, y+height)\n",
    "        for l in roi.iterfind(\"./OME:Union/OME:Label\", ns):\n",
    "            text = l.attrib[\"Text\"]\n",
    "            \n",
    "        print(a,b)\n",
    "        layer.annotations.append(\n",
    "            neuroglancer.AxisAlignedBoundingBoxAnnotation(\n",
    "                description=text,\n",
    "                id=neuroglancer.random_token.make_random_token(),\n",
    "                point_a=a,\n",
    "                point_b=b\n",
    "            )\n",
    "        )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3583fa67-80dd-4e72-b802-db331c3ba81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_ng_shader(path, key):\n",
    "    global  shader_parameter_cache\n",
    "    \n",
    "    hwz_images = HedwigZarrImages(path)\n",
    "    hwz_image = hwz_images[list(hwz_images.get_series_keys())[key]]\n",
    "    \n",
    "    rgb_shader_code=\"\"\"\n",
    "void main() {\n",
    "  emitRGB(vec3(toNormalized(getDataValue(0)),\n",
    "               toNormalized(getDataValue(1)),\n",
    "               toNormalized(getDataValue(2))));\n",
    "}\n",
    "\"\"\"\n",
    "    \n",
    "    if hwz_image.shader_type == \"RGB\":\n",
    "        return rgb_shader_code    \n",
    "        \n",
    "    \n",
    "    if (path, key) not in shader_parameter_cache:\n",
    "\n",
    "        shader_parameter_cache[(path, key)] = hwz_image.neuroglancer_shader_parameters(middle_quantile=[0.01, 0.999])\n",
    "    \n",
    "    params = shader_parameter_cache[(path, key)]\n",
    "    \n",
    "    template = \"\"\"\n",
    "#uicontrol float brightness slider(default={{brightness}}, min=-1, max=1, step=0.1)\n",
    "#uicontrol float contrast slider(default={{contrast}}, min=-3, max=3, step=0.1)\n",
    "    \n",
    "{% for channel in channelArray %}\n",
    "#uicontrol bool {{channel.name}} checkbox(default=true)\n",
    "#uicontrol vec3 color{{channel.channel}} color(default=\"{{channel.color}}\")\n",
    "#uicontrol invlerp invlerp{{channel.channel}}(range=[{{channel.range[0]}}, {{channel.range[1]}}], window=[{{channel.window[0]}}, {{channel.window[1]}}], channel={{channel.channel}}, clamp=true)\n",
    "{% endfor %}\n",
    "\n",
    "void main() {\n",
    "    vec3 cum = vec3(0., 0., 0.);\n",
    "    {% for channel in channelArray %}\n",
    "    if ({{channel.name}})\n",
    "    {\n",
    "        cum += color{{channel.channel}} * invlerp{{channel.channel}}(getDataValue({{channel.channel}}));\n",
    "    }\n",
    "    {% endfor %}\n",
    "    emitRGB((cum+brightness)*exp(contrast));\n",
    "}\n",
    "\"\"\"\n",
    "    \n",
    "    j2_template = jinja2.Template(template)\n",
    "    shader_code = j2_template.render(params)\n",
    "    \n",
    "    return shader_code\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e19791-5228-416c-9205-5a29fdf37106",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_sitk_image(img:sitk.Image, name=\"image\", transform=None, shader_code=None):\n",
    "    \n",
    "    img = img.ToScalarImage(inPlace=False)\n",
    "    assert(img.GetDimension()==3)\n",
    "\n",
    "    dimensions=neuroglancer.CoordinateSpace(\n",
    "                                           names=['y', 'x', 'c^'],\n",
    "                                           units=[\"nm\", \"nm\", \"\"],\n",
    "                                           scales=img.GetSpacing()[::-1])\n",
    "                            \n",
    "\n",
    "    ng_transform = None\n",
    "    M = homogeneous_identity(3)\n",
    "    if transform:\n",
    "        print(transform.GetName())\n",
    "        if transform.GetName() == \"TranslationTransform\":\n",
    "            transform = sitk.AffineTransform(np.identity(2, dtype=float).flatten(), transform.GetOffset())\n",
    "         \n",
    "        tx_matrix = np.array(transform.GetMatrix()).reshape(transform.GetDimension(),transform.GetDimension())\n",
    "\n",
    "        M[1,1] = tx_matrix[0,0]\n",
    "        M[0,1] = tx_matrix[1,0]\n",
    "        M[1,0] = tx_matrix[0,1]\n",
    "        M[0,0] = tx_matrix[1,1]    \n",
    "        \n",
    "        tx_translation = sitk_offset_from_transform(transform)\n",
    "        tx_translation = [t/s for t,s in zip(tx_translation, img.GetSpacing()[1:])]\n",
    "        #M[0,3] = tx_translation[1]\n",
    "        #M[1,3] = tx_translation[0]\n",
    "    \n",
    "        print(tx_translation)\n",
    "        \n",
    "    ng_transform = neuroglancer.CoordinateSpaceTransform(output_dimensions=dimensions,\n",
    "                                                         matrix = M)\n",
    "\n",
    "    volume = neuroglancer.LocalVolume( sitk.GetArrayViewFromImage(img), dimensions=dimensions )\n",
    "             \n",
    "                                                                                     \n",
    "    with viewer.txn() as s:\n",
    "      layer = neuroglancer.ImageLayer(\n",
    "            source=neuroglancer.LayerDataSource(volume, transform=ng_transform),\n",
    "            shader=shader_code,\n",
    "      )\n",
    "      s.layers[name] = layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba96c94a793418",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shader_parameter_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2edc1c09ca84ac5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with viewer.txn() as s:\n",
    "  dimensions = neuroglancer.CoordinateSpace( names=[\"x\", \"y\", \"z\"], units =[\"nm\",\"nm\", \"nm\"], scales=[1,1,1])\n",
    "  s.dimensions = dimensions\n",
    "  s.layout = neuroglancer.DataPanelLayout(\"xy\")\n",
    "  \n",
    "  s.layers.clear()\n",
    "\n",
    "  add_zarr_image(s,\"IA_P2_S1.ome.zarr/0\")\n",
    "  \n",
    "  add_zarr_image(s, \"IA_P2_S4.zarr/0\", file_dir/\"IA_P2_S4_0_to_roi.txt\")\n",
    "  add_zarr_image(s, \"IA_P2_S4.zarr/1\", file_dir/\"IA_P2_S4_1_to_roi.txt\")\n",
    "  \n",
    "  add_roi_annotations(s, Path(file_dir)/ \"IA_P2_S1.ome.zarr/OME/METADATA.ome.xml\",\n",
    "                      layername=\"roi annotation\",\n",
    "                      reference_zarr=Path(file_dir)/\"IA_P2_S4.ome.zarr\"/\"0\")\n",
    "print(viewer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a96d34fc488b9a6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with viewer.txn() as s:\n",
    "  dimensions = neuroglancer.CoordinateSpace( names=[\"x\", \"y\", \"z\"], units =[\"nm\",\"nm\", \"nm\"], scales=[1,1,1])\n",
    "  s.dimensions = dimensions\n",
    "  s.layout = neuroglancer.DataPanelLayout(\"xy\")\n",
    "\n",
    "  s.layers.clear()\n",
    "\n",
    "  add_zarr_image(s, file_dir/\"IA_P2_S2.ome.zarr/0\", server_url=server.url)\n",
    "  \n",
    "  add_zarr_image(s, file_dir/\"IA_P2_S2.zarr/0\", server.url, file_dir/\"IA_P2_S2_0_to_roi.txt\")\n",
    "  add_zarr_image(s, file_dir/\"IA_P2_S2.zarr/1\", server.url, file_dir/\"IA_P2_S2_1_to_roi.txt\")\n",
    " \n",
    "  add_roi_annotations(s, Path(file_dir)/ \"IA_P2_S2.ome.zarr/OME/METADATA.ome.xml\")\n",
    "print(viewer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eae17a-1da0-404c-b7ce-d1648a904b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "with viewer.txn() as s:\n",
    "  dimensions = neuroglancer.CoordinateSpace( names=[\"x\", \"y\", \"z\"], units =[\"nm\",\"nm\", \"nm\"], scales=[1,1,1])\n",
    "  s.dimensions = dimensions\n",
    "  s.layout = neuroglancer.DataPanelLayout(\"xy\")\n",
    "  \n",
    "  s.layers.clear()\n",
    "  \n",
    "  add_zarr_image(s, \"IA_P2_S3.ome.zarr/0\")\n",
    "  \n",
    "  add_zarr_image(s, \"IA_P2_S3.zarr/0\", file_dir/\"IA_P2_S3_0_to_roi.txt\")\n",
    "  add_zarr_image(s, \"IA_P2_S3.zarr/1\", file_dir/\"IA_P2_S3_1_to_roi.txt\")\n",
    "\n",
    "  add_roi_annotations(s, Path(file_dir)/ \"IA_P2_S3.ome.zarr/OME/METADATA.ome.xml\")\n",
    "\n",
    "print(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82495f65-5634-45cd-91a3-0792f03dd941",
   "metadata": {},
   "outputs": [],
   "source": [
    "with viewer.txn() as s:\n",
    "  dimensions = neuroglancer.CoordinateSpace( names=[\"x\", \"y\", \"z\"], units =[\"nm\",\"nm\", \"nm\"], scales=[1,1,1])\n",
    "  s.dimensions = dimensions\n",
    "  s.layout = neuroglancer.DataPanelLayout(\"xy\")\n",
    "\n",
    "  s.layers.clear()\n",
    "\n",
    "  add_zarr_image(s, \"IA_P2_S4.ome.zarr/0\")\n",
    "  \n",
    "  add_zarr_image(s, \"IA_P2_S1.zarr/0\", file_dir/\"IA_P2_S1_0_to_roi.txt\")\n",
    "  add_zarr_image(s, \"IA_P2_S1.zarr/1\", file_dir/\"IA_P2_S1_1_to_roi.txt\")\n",
    "\n",
    "  add_roi_annotations(s, Path(file_dir)/ \"IA_P2_S4.ome.zarr/OME/METADATA.ome.xml\")\n",
    "print(viewer)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
